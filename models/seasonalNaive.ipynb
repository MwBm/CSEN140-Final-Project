{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7207ad0b",
   "metadata": {},
   "source": [
    "# SeasonalNaive model based on prior weeks wait times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8b187",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd70f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a8377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/vwp6cpmd6xd962fpyb8gjv5w0000gn/T/ipykernel_88545/1020655066.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_merged_df = pd.read_csv('../data/final_merged_data.csv', parse_dates=['Local Time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 589,985 records\n",
      "Number of unique rides: 42\n",
      "\n",
      "Unique rides:\n",
      "  Animation Academy: 18,021 records\n",
      "  Games of Pixar Pier: 16,166 records\n",
      "  Golden Zephyr: 18,021 records\n",
      "  Goofy's Sky School: 18,021 records\n",
      "  Grizzly River Run: 18,021 records\n",
      "  Guardians of the Galaxy - Mission: BREAKOUT!: 18,021 records\n",
      "  Guardians of the Galaxy - Monsters After Dark: 9,754 records\n",
      "  Incredicoaster: 18,021 records\n",
      "  Incredicoaster Single Rider: 18,021 records\n",
      "  Inside Out Emotional Whirlwind: 18,021 records\n",
      "  Jessie's Critter Carousel: 18,021 records\n",
      "  Jumpin' Jellyfish: 18,021 records\n",
      "  Luigi's Honkin' Haul-O-Ween: 1,516 records\n",
      "  Luigi's Joy to the Whirl: 3,087 records\n",
      "  Luigi's Rollickin' Roadsters: 11,564 records\n",
      "  Mater's Graveyard JamBOOree: 3,344 records\n",
      "  Mater's Jingle Jamboree: 3,087 records\n",
      "  Mater's Junkyard Jamboree: 11,590 records\n",
      "  Mickey's PhilharMagic: 18,021 records\n",
      "  Monsters, Inc. Mike & Sulley to the Rescue!: 18,021 records\n",
      "  Pixar Pal-A-Round - Swinging: 18,021 records\n",
      "  Pixar Pal-A-Round – Non-Swinging: 18,021 records\n",
      "  Radiator Springs Racers: 18,021 records\n",
      "  Radiator Springs Racers Single Rider: 18,021 records\n",
      "  Red Car Trolley: 16,847 records\n",
      "  Redwood Creek Challenge Trail: 18,021 records\n",
      "  Rogers: The Musical: 1,378 records\n",
      "  Silly Symphony Swings: 18,021 records\n",
      "  Silly Symphony Swings Single Rider: 18,021 records\n",
      "  Soarin' Around the World: 15,120 records\n",
      "  Soarin' Over California: 2,901 records\n",
      "  Sorcerer's Workshop: 18,021 records\n",
      "  The Bakery Tour: 16,166 records\n",
      "  The Little Mermaid - Ariel's Undersea Adventure: 18,021 records\n",
      "  Toy Story Midway Mania!: 18,021 records\n",
      "  Turtle Talk with Crush: 18,021 records\n",
      "  Villains Grove at Oogie Boogie Bash: 3,259 records\n",
      "  WEB SLINGERS: A Spider-Man Adventure: 18,021 records\n",
      "  WEB SLINGERS: A Spider-Man Adventure Single Rider: 18,021 records\n",
      "  Walt Disney Imagineering Blue Sky Cellar: 1,378 records\n",
      "  World of Color - Season of Light: 4,282 records\n",
      "  World of Color – ONE: 18,021 records\n"
     ]
    }
   ],
   "source": [
    "final_merged_df = pd.read_csv('../data/final_merged_data.csv', parse_dates=['Local Time'])\n",
    "\n",
    "# Print preliminary data\n",
    "print(f\"Loaded {len(final_merged_df):,} records\")\n",
    "print(f\"Number of unique rides: {final_merged_df['Ride'].nunique()}\")\n",
    "\n",
    "# Print a list of all unique ride names along with the number of records for each ride.\n",
    "# Using value_counts() which is more reliable than manual counting\n",
    "print(f\"\\nUnique rides:\")\n",
    "ride_counts = final_merged_df['Ride'].value_counts().sort_index()\n",
    "for ride, count in ride_counts.items():\n",
    "    print(f\"  {ride}: {count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af89d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rides before filtering: 42\n",
      "Total records before filtering: 589,985\n",
      "Rides after filtering: 20\n",
      "Total records after filtering: 344,631\n",
      "\n",
      "Dropped rides:\n",
      "  - Animation Academy\n",
      "  - Games of Pixar Pier\n",
      "  - Guardians of the Galaxy - Monsters After Dark\n",
      "  - Luigi's Honkin' Haul-O-Ween\n",
      "  - Luigi's Joy to the Whirl\n",
      "  - Mater's Graveyard JamBOOree\n",
      "  - Mater's Jingle Jamboree\n",
      "  - Red Car Trolley\n",
      "  - Redwood Creek Challenge Trail\n",
      "  - The Bakery Tour\n",
      "  - Sorcerer's Workshop\n",
      "  - Soarin' Over California\n",
      "  - Rogers: The Musical\n",
      "  - Walt Disney Imagineering Blue Sky Cellar\n",
      "  - Turtle Talk with Crush\n",
      "  - Mickey's PhilharMagic\n",
      "  - World of Color – ONE\n",
      "  - World of Color - Season of Light\n",
      "  - Villains Grove at Oogie Boogie Bash\n",
      "  - Silly Symphony Swings Single Rider\n",
      "  - Incredicoaster Single Rider\n",
      "  - Radiator Springs Racers Single Rider\n"
     ]
    }
   ],
   "source": [
    "# Dropping rides that are redundant/stupid\n",
    "rides_to_drop = [\n",
    "    'Animation Academy',\n",
    "    'Games of Pixar Pier',\n",
    "    'Guardians of the Galaxy - Monsters After Dark',\n",
    "    'Luigi\\'s Honkin\\' Haul-O-Ween',\n",
    "    'Luigi\\'s Joy to the Whirl',\n",
    "    'Mater\\'s Graveyard JamBOOree',\n",
    "    'Mater\\'s Jingle Jamboree',\n",
    "    'Red Car Trolley',\n",
    "    'Redwood Creek Challenge Trail',\n",
    "    'The Bakery Tour',\n",
    "    'Sorcerer\\'s Workshop',\n",
    "    'Soarin\\' Over California',\n",
    "    'Rogers: The Musical', \n",
    "    'Walt Disney Imagineering Blue Sky Cellar', \n",
    "    'Turtle Talk with Crush', \n",
    "    'Mickey\\'s PhilharMagic',\n",
    "    'World of Color – ONE',\n",
    "    'World of Color - Season of Light',\n",
    "    'Villains Grove at Oogie Boogie Bash',\n",
    "    'Silly Symphony Swings Single Rider',\n",
    "    'Incredicoaster Single Rider',\n",
    "    'Radiator Springs Racers Single Rider'\n",
    "]\n",
    "\n",
    "print(f\"Rides before filtering: {final_merged_df['Ride'].nunique()}\")\n",
    "print(f\"Total records before filtering: {len(final_merged_df):,}\")\n",
    "\n",
    "# Filter out the specified rides\n",
    "final_merged_df = final_merged_df[~final_merged_df['Ride'].isin(rides_to_drop)]\n",
    "\n",
    "print(f\"Rides after filtering: {final_merged_df['Ride'].nunique()}\")\n",
    "print(f\"Total records after filtering: {len(final_merged_df):,}\")\n",
    "\n",
    "print(f\"\\nDropped rides:\")\n",
    "for ride in rides_to_drop:\n",
    "    print(f\"  - {ride}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86966e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the main dataset into separate, time-sorted DataFrames for each\n",
    "# ride and store them in a dictionary for easy per-ride analysis.\n",
    "ride_dataframes = {}\n",
    "\n",
    "for ride in final_merged_df['Ride'].unique():\n",
    "    ride_df = final_merged_df[final_merged_df['Ride'] == ride].copy()\n",
    "    ride_df = ride_df.sort_values('Local Time').reset_index(drop=True)\n",
    "    ride_dataframes[ride] = ride_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e0409",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9190f520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardians of the Galaxy - Mission: BREAKOUT!: Seasonal Naive MAE = 33.87 minutes\n",
      "Golden Zephyr: Seasonal Naive MAE = 6.26 minutes\n",
      "Goofy's Sky School: Seasonal Naive MAE = 23.17 minutes\n",
      "Silly Symphony Swings: Seasonal Naive MAE = 7.14 minutes\n",
      "The Little Mermaid - Ariel's Undersea Adventure: Seasonal Naive MAE = 14.35 minutes\n",
      "Incredicoaster: Seasonal Naive MAE = 22.38 minutes\n",
      "Inside Out Emotional Whirlwind: Seasonal Naive MAE = 12.62 minutes\n",
      "Jessie's Critter Carousel: Seasonal Naive MAE = 2.30 minutes\n",
      "Jumpin' Jellyfish: Seasonal Naive MAE = 7.02 minutes\n",
      "Pixar Pal-A-Round - Swinging: Seasonal Naive MAE = 19.78 minutes\n",
      "Pixar Pal-A-Round – Non-Swinging: Seasonal Naive MAE = 18.51 minutes\n",
      "Toy Story Midway Mania!: Seasonal Naive MAE = 21.41 minutes\n",
      "WEB SLINGERS: A Spider-Man Adventure: Seasonal Naive MAE = 21.94 minutes\n",
      "WEB SLINGERS: A Spider-Man Adventure Single Rider: Seasonal Naive MAE = 0.00 minutes\n",
      "Luigi's Rollickin' Roadsters: Seasonal Naive MAE = 15.86 minutes\n",
      "Mater's Junkyard Jamboree: Seasonal Naive MAE = 12.25 minutes\n",
      "Radiator Springs Racers: Seasonal Naive MAE = 37.97 minutes\n",
      "Soarin' Around the World: Seasonal Naive MAE = 24.79 minutes\n",
      "Monsters, Inc. Mike & Sulley to the Rescue!: Seasonal Naive MAE = 21.84 minutes\n",
      "Grizzly River Run: Seasonal Naive MAE = 15.47 minutes\n"
     ]
    }
   ],
   "source": [
    "baseline_results = {}\n",
    "\n",
    "# Loop over each ride's data\n",
    "for ride, df in ride_dataframes.items():\n",
    "    \n",
    "    # Feature Engineering (make raw data easier to use)\n",
    "    df['hour'] = df['Local Time'].dt.hour\n",
    "    df['day_of_week'] = df['Local Time'].dt.dayofweek\n",
    "    df['month'] = df['Local Time'].dt.month\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "    \n",
    "    # Create a Seasonal Naive feature\n",
    "    # Prediction = wait time at same time last week\n",
    "    lag = 7*24*4                                                # Data is at 15-minute intervals, so lag = 7 days * 24 hours * 4 intervals/hour = 672\n",
    "    df['Predicted Wait Time'] = df['Wait Time'].shift(lag)\n",
    "    df.dropna(subset=['Predicted Wait Time'], inplace=True)     # Drop first week of rows that have no \"previous week\" value\n",
    "    \n",
    "    # Calculate baseline error (average absolute difference between predicted and actual wait times)\n",
    "    mae = mean_absolute_error(df['Wait Time'], df['Predicted Wait Time'])\n",
    "    baseline_results[ride] = mae\n",
    "    \n",
    "    # Save the updated DataFrame back to the dictionary\n",
    "    ride_dataframes[ride] = df\n",
    "\n",
    "# Display baseline MAE for each ride\n",
    "for ride, mae in baseline_results.items():\n",
    "    print(f\"{ride}: Seasonal Naive MAE = {mae:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
